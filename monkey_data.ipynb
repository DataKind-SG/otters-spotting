{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "monkey_data.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DataKind-SG/otters-spotting/blob/master/monkey_data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BEN-PgpC5PQ8",
        "colab_type": "text"
      },
      "source": [
        "# Extract Identified Monkeys in Bounding Boxes\n",
        "\n",
        "Uses pretrained object detection model in Tensorflow\n",
        "\n",
        "Potential improvements:\n",
        "1. Currently takes the first monkey that is detected, also doesn't throw an error if no monkey is detected.\n",
        "2. Too slow, 1 min / pic."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cVGKBoJNLFCU",
        "colab_type": "text"
      },
      "source": [
        "**Mount Google Drive**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6OHloCDwLI4y",
        "colab_type": "code",
        "outputId": "f5992bbe-dcc8-4853-8816-62c63f4e2f2f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive/')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bWVUKnaELZMI",
        "colab_type": "text"
      },
      "source": [
        "**Clone Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jiNJVna3JNqx",
        "colab_type": "code",
        "outputId": "3248c468-3bf5-4dee-cff2-65e480a71cfd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 476
        }
      },
      "source": [
        "!git clone https://github.com/tensorflow/models.git\n",
        "!apt-get -qq install libprotobuf-java protobuf-compiler\n",
        "!protoc ./models/research/object_detection/protos/string_int_label_map.proto --python_out=.\n",
        "!cp -R models/research/object_detection/ object_detection/\n",
        "!rm -rf models"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'models'...\n",
            "remote: Enumerating objects: 6, done.\u001b[K\n",
            "remote: Counting objects: 100% (6/6), done.\u001b[K\n",
            "remote: Compressing objects: 100% (6/6), done.\u001b[K\n",
            "remote: Total 21658 (delta 0), reused 0 (delta 0), pack-reused 21652\u001b[K\n",
            "Receiving objects: 100% (21658/21658), 559.41 MiB | 33.85 MiB/s, done.\n",
            "Resolving deltas: 100% (12712/12712), done.\n",
            "Checking out files: 100% (2809/2809), done.\n",
            "Selecting previously unselected package libprotobuf10:amd64.\n",
            "(Reading database ... 18408 files and directories currently installed.)\n",
            "Preparing to unpack .../libprotobuf10_3.0.0-9ubuntu5_amd64.deb ...\n",
            "Unpacking libprotobuf10:amd64 (3.0.0-9ubuntu5) ...\n",
            "Selecting previously unselected package libprotoc10:amd64.\n",
            "Preparing to unpack .../libprotoc10_3.0.0-9ubuntu5_amd64.deb ...\n",
            "Unpacking libprotoc10:amd64 (3.0.0-9ubuntu5) ...\n",
            "Selecting previously unselected package libprotobuf-java.\n",
            "Preparing to unpack .../libprotobuf-java_3.0.0-9ubuntu5_all.deb ...\n",
            "Unpacking libprotobuf-java (3.0.0-9ubuntu5) ...\n",
            "Selecting previously unselected package protobuf-compiler.\n",
            "Preparing to unpack .../protobuf-compiler_3.0.0-9ubuntu5_amd64.deb ...\n",
            "Unpacking protobuf-compiler (3.0.0-9ubuntu5) ...\n",
            "Setting up libprotobuf-java (3.0.0-9ubuntu5) ...\n",
            "Setting up libprotobuf10:amd64 (3.0.0-9ubuntu5) ...\n",
            "Processing triggers for libc-bin (2.26-0ubuntu2.1) ...\n",
            "Setting up libprotoc10:amd64 (3.0.0-9ubuntu5) ...\n",
            "Setting up protobuf-compiler (3.0.0-9ubuntu5) ...\n",
            "Processing triggers for libc-bin (2.26-0ubuntu2.1) ...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qBff1eOzLdDI",
        "colab_type": "text"
      },
      "source": [
        "**Import necessary packages**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BGb5YPLgJ6Hm",
        "colab_type": "code",
        "outputId": "a784469d-5b9b-42a6-ba8c-8456ce8db3f5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 663
        }
      },
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import six.moves.urllib as urllib\n",
        "import sys\n",
        "import tarfile\n",
        "import tensorflow as tf\n",
        "import zipfile\n",
        "import re\n",
        "\n",
        "from collections import defaultdict\n",
        "from io import StringIO\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "from PIL import Image\n",
        "\n",
        "from object_detection.utils import label_map_util\n",
        "from object_detection.utils import visualization_utils as vis_util"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/object_detection/utils/visualization_utils.py:27: UserWarning: \n",
            "This call to matplotlib.use() has no effect because the backend has already\n",
            "been chosen; matplotlib.use() must be called *before* pylab, matplotlib.pyplot,\n",
            "or matplotlib.backends is imported for the first time.\n",
            "\n",
            "The backend was *originally* set to 'module://ipykernel.pylab.backend_inline' by the following code:\n",
            "  File \"/usr/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n",
            "    \"__main__\", mod_spec)\n",
            "  File \"/usr/lib/python3.6/runpy.py\", line 85, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n",
            "    app.launch_new_instance()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/traitlets/config/application.py\", line 657, in launch_instance\n",
            "    app.initialize(argv)\n",
            "  File \"<decorator-gen-121>\", line 2, in initialize\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/traitlets/config/application.py\", line 87, in catch_config_error\n",
            "    return method(app, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelapp.py\", line 462, in initialize\n",
            "    self.init_gui_pylab()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelapp.py\", line 403, in init_gui_pylab\n",
            "    InteractiveShellApp.init_gui_pylab(self)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/shellapp.py\", line 213, in init_gui_pylab\n",
            "    r = enable(key)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2950, in enable_matplotlib\n",
            "    pt.activate_matplotlib(backend)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/pylabtools.py\", line 309, in activate_matplotlib\n",
            "    matplotlib.pyplot.switch_backend(backend)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/matplotlib/pyplot.py\", line 232, in switch_backend\n",
            "    matplotlib.use(newbackend, warn=False, force=True)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/matplotlib/__init__.py\", line 1305, in use\n",
            "    reload(sys.modules['matplotlib.backends'])\n",
            "  File \"/usr/lib/python3.6/importlib/__init__.py\", line 166, in reload\n",
            "    _bootstrap._exec(spec, module)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/matplotlib/backends/__init__.py\", line 14, in <module>\n",
            "    line for line in traceback.format_stack()\n",
            "\n",
            "\n",
            "  import matplotlib; matplotlib.use('Agg')  # pylint: disable=multiple-statements\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AWU3tn_ytXEP",
        "colab_type": "text"
      },
      "source": [
        "**Check GPU allocated**\n",
        "\n",
        "Note: without GPU it's quite slow."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pRn0cwoJsrN4",
        "colab_type": "code",
        "outputId": "e38e34d8-5550-4df1-f1a0-6073906ed170",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MFlcFL8eI3xx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Check whether monkey image is inside the drive\n",
        "# This set up assumes that you've got a Dir named \"monkey_image\" on your google drive root that have all the images\n",
        "# And a sub-directory in that folder called \"monkey_image_processed\" where the cropped photos will be stored.\n",
        "# !ls \"/content/gdrive/My Drive/monkey_image\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MtWFq-FJKOBu",
        "colab_type": "text"
      },
      "source": [
        "**Download model for processing**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XunKw_LDKPbf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# What model to download.\n",
        "# MODEL_NAME = 'ssd_mobilenet_v1_coco_2017_11_17'\n",
        "\n",
        "# model with more accurancy but up to you use a diferent model\n",
        "MODEL_NAME = 'faster_rcnn_inception_resnet_v2_atrous_lowproposals_oid_2018_01_28'\n",
        "\n",
        "MODEL_FILE = MODEL_NAME + '.tar.gz'\n",
        "DOWNLOAD_BASE = 'http://download.tensorflow.org/models/object_detection/'\n",
        "\n",
        "# Path to frozen detection graph. This is the actual model that is used for the object detection.\n",
        "PATH_TO_CKPT = MODEL_NAME + '/frozen_inference_graph.pb'\n",
        "\n",
        "# List of the strings that is used to add correct label for each box.\n",
        "PATH_TO_LABELS = os.path.join('object_detection/data', 'oid_bbox_trainable_label_map.pbtxt')\n",
        "\n",
        "NUM_CLASSES = 90\n",
        "\n",
        "opener = urllib.request.URLopener()\n",
        "opener.retrieve(DOWNLOAD_BASE + MODEL_FILE, MODEL_FILE)\n",
        "tar_file = tarfile.open(MODEL_FILE)\n",
        "for file in tar_file.getmembers():\n",
        "  file_name = os.path.basename(file.name)\n",
        "  if 'frozen_inference_graph.pb' in file_name:\n",
        "    tar_file.extract(file, os.getcwd())\n",
        "    \n",
        "detection_graph = tf.Graph()\n",
        "with detection_graph.as_default():\n",
        "  od_graph_def = tf.GraphDef()\n",
        "  with tf.gfile.GFile(PATH_TO_CKPT, 'rb') as fid:\n",
        "    serialized_graph = fid.read()\n",
        "    od_graph_def.ParseFromString(serialized_graph)\n",
        "    tf.import_graph_def(od_graph_def, name='')\n",
        "    \n",
        "label_map = label_map_util.load_labelmap(PATH_TO_LABELS)\n",
        "categories = label_map_util.convert_label_map_to_categories(label_map, max_num_classes=NUM_CLASSES, use_display_name=True)\n",
        "category_index = label_map_util.create_category_index(categories)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1EHM4GCdLjvU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_image_into_numpy_array(image):\n",
        "  (im_width, im_height) = image.size\n",
        "  return np.array(image.getdata()).reshape(\n",
        "      (im_height, im_width, 3)).astype(np.uint8)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DK-AtPH9Ltvh",
        "colab_type": "text"
      },
      "source": [
        "**Loading label map**\n",
        "\n",
        "Monkey is 169"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UAO-MhPmLxgg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "label_map = label_map_util.load_labelmap(PATH_TO_LABELS)\n",
        "categories = label_map_util.convert_label_map_to_categories(label_map, max_num_classes=NUM_CLASSES, use_display_name=True)\n",
        "category_index = label_map_util.create_category_index(categories)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VDCEdf9CLy_5",
        "colab_type": "text"
      },
      "source": [
        "**Helper code**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XrMrF9ByL1go",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_image_into_numpy_array(image):\n",
        "  (im_width, im_height) = image.size\n",
        "  return np.array(image.getdata()).reshape(\n",
        "      (im_height, im_width, 3)).astype(np.uint8)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hir9uwqZL4Xp",
        "colab_type": "text"
      },
      "source": [
        "**Find the directory and the images**\n",
        "\n",
        "Will need to change later when we have more than 219 images."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BDOFuodbL9nK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "PATH_TO_TEST_IMAGES_DIR = '/content/gdrive/My Drive/monkey_image'\n",
        "PATH_TO_OUTPUT_IMAGES_DIR = '/content/gdrive/My Drive/monkey_image/monkey_images_processed'\n",
        "CONTAINED_IMAGE_PATHS = [f for f in os.listdir(PATH_TO_TEST_IMAGES_DIR) if f.endswith('.jpg')]\n",
        "TEST_IMAGE_PATHS = set(CONTAINED_IMAGE_PATHS) - set(os.listdir(PATH_TO_OUTPUT_IMAGES_DIR))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZnNEfcLyMS4w",
        "colab_type": "text"
      },
      "source": [
        "**Run Inference for a single image**\n",
        "\n",
        "This need to be put in a loop later on."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hx1XSIZfMXTU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def run_inference_for_single_image(image, graph):\n",
        "  with graph.as_default():\n",
        "    with tf.Session(config=tf.ConfigProto(log_device_placement=True)) as sess:\n",
        "      # Get handles to input and output tensors\n",
        "      ops = tf.get_default_graph().get_operations()\n",
        "      all_tensor_names = {output.name for op in ops for output in op.outputs}\n",
        "      tensor_dict = {}\n",
        "      for key in [\n",
        "          'num_detections', 'detection_boxes', 'detection_scores',\n",
        "          'detection_classes', 'detection_masks'\n",
        "      ]:\n",
        "        tensor_name = key + ':0'\n",
        "        if tensor_name in all_tensor_names:\n",
        "          tensor_dict[key] = tf.get_default_graph().get_tensor_by_name(\n",
        "              tensor_name)\n",
        "      if 'detection_masks' in tensor_dict:\n",
        "        # The following processing is only for single image\n",
        "        detection_boxes = tf.squeeze(tensor_dict['detection_boxes'], [0])\n",
        "        detection_masks = tf.squeeze(tensor_dict['detection_masks'], [0])\n",
        "        # Reframe is required to translate mask from box coordinates to image coordinates and fit the image size.\n",
        "        real_num_detection = tf.cast(tensor_dict['num_detections'][0], tf.int32)\n",
        "        detection_boxes = tf.slice(detection_boxes, [0, 0], [real_num_detection, -1])\n",
        "        detection_masks = tf.slice(detection_masks, [0, 0, 0], [real_num_detection, -1, -1])\n",
        "        detection_masks_reframed = utils_ops.reframe_box_masks_to_image_masks(\n",
        "            detection_masks, detection_boxes, image.shape[0], image.shape[1])\n",
        "        detection_masks_reframed = tf.cast(\n",
        "            tf.greater(detection_masks_reframed, 0.5), tf.uint8)\n",
        "        # Follow the convention by adding back the batch dimension\n",
        "        tensor_dict['detection_masks'] = tf.expand_dims(\n",
        "            detection_masks_reframed, 0)\n",
        "      image_tensor = tf.get_default_graph().get_tensor_by_name('image_tensor:0')\n",
        "\n",
        "      # Run inference\n",
        "      output_dict = sess.run(tensor_dict,\n",
        "                             feed_dict={image_tensor: np.expand_dims(image, 0)})\n",
        "\n",
        "      # all outputs are float32 numpy arrays, so convert types as appropriate\n",
        "      output_dict['num_detections'] = int(output_dict['num_detections'][0])\n",
        "      output_dict['detection_classes'] = output_dict[\n",
        "          'detection_classes'][0].astype(np.uint8)\n",
        "      output_dict['detection_boxes'] = output_dict['detection_boxes'][0]\n",
        "      output_dict['detection_scores'] = output_dict['detection_scores'][0]\n",
        "      if 'detection_masks' in output_dict:\n",
        "        output_dict['detection_masks'] = output_dict['detection_masks'][0]\n",
        "  return output_dict"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vtSMeeYRMa51",
        "colab_type": "text"
      },
      "source": [
        "**Label images**\n",
        "\n",
        "Will keep time out on Colab about every 30+ mins as they do not allow long jobs. Current speed with GPU is about 1 min / pic. Speed up over CPU is not significant, not sure what I'm doing wrong.\n",
        "\n",
        "Currently takes the first monkey that is detected, also doesn't throw an error if no monkey is detected."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6rVL-USMMdOl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for image_path in TEST_IMAGE_PATHS:\n",
        "    INPUT_IMAGE_PATH = os.path.join(PATH_TO_TEST_IMAGES_DIR, image_path)\n",
        "    \n",
        "    # Stores image in the output directory\n",
        "    OUTPUT_IMAGE_PATH = os.path.join(PATH_TO_OUTPUT_IMAGES_DIR, image_path)\n",
        "    image = Image.open(INPUT_IMAGE_PATH)\n",
        "    # the array based representation of the image will be used later in order to prepare the\n",
        "    # result image with boxes and labels on it.\n",
        "    image_np = load_image_into_numpy_array(image)\n",
        "    # Expand dimensions since the model expects images to have shape: [1, None, None, 3]\n",
        "    image_np_expanded = np.expand_dims(image_np, axis=0)\n",
        "    # Actual detection.\n",
        "    output_dict = run_inference_for_single_image(image_np, detection_graph)\n",
        "    # Retrieve the first box labelled as monkey.\n",
        "    # Catch instances where no monkey is detected, but could be improved to throw an error as well.\n",
        "    if np.sum([output_dict['detection_classes'] == 169, ]) != 0:\n",
        "      x, y = image.size\n",
        "      ymin, xmin, ymax, xmax = output_dict['detection_boxes'][output_dict['detection_classes'] == 169, ][0]\n",
        "      coords = (xmin * x, ymin * y, xmax * x, ymax * y)\n",
        "      cropped_image = image.crop(coords)\n",
        "      cropped_image.save(OUTPUT_IMAGE_PATH)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X-l6p_0GsBbK",
        "colab_type": "code",
        "outputId": "dcbe27b0-4a1a-4a18-b9d0-2dd22a7f6d0a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "# Cell to test stuff\n",
        "TEST_IMAGE_PATHS"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'image_00038.jpg',\n",
              " 'image_00043.jpg',\n",
              " 'image_00167.jpg',\n",
              " 'image_00176.jpg',\n",
              " 'image_00204.jpg',\n",
              " 'image_00206.jpg'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    }
  ]
}